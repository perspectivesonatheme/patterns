When the interpretation {inference} is more precise than the data.

Confusing noise for signal.\
Treating a sample of the probability distribution as the value itself.\
Disregarding any uncertainty in the value.

Apophenia: the human tendency to see patterns where none exist\
Clustering illusion

Relation to Goodhart's law (optimizing a metric at the expense of others)

Overfitting can happen both when inferring a model from a dataset (e.g. fitting a climate model to daily weather), and also when interpreting {extracting data from} a model (e.g. predicting daily weather from a climate model).

Examples:
- species overfitting to a particular climate; humans are successful in part due to our adaptabilityâ€”we're generalists
- people overfitting to a particular era ([hell in a handbasket](Ignorance.md#hell-in-a-handbasket))
- learning specific practical skills at a tech school vs building a foundation in a field at a university; tech school teach skills which better fit current labor demands, at the risk of overfitting (making it more difficult to adapt to new labor demands)
- over-/premature-optimization: optimizing before the overall design is settled, or optimizing past the point at which it no longer adds value
- overfitting to language
	- to a single language (this is one reason why learning foreign languages is valuable)
	- overfitting thought to the proxy/projection/samples of language
- over-interpretation of an artwork or what someone says: inferring more than was intended by the artist or speaker
- "jack of all trades, master of none" (underfitting) vs "one trick pony" (overfitting)
- learning to play piano by practicing only a single song

Underfitting:
- oversimplification
- facile
- analysis paralysis

[proxies](Proxies.md)\
[priming](Priming.md): a prior is a guard against overfitting to new evidence\
[occam's razor](Occam's%20razor.md)
